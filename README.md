# GPT-2-Tutorials
```markdown
Q: 这是什么？
A: 这是一份GPT-2的学习代码(GPT_2 Tutorials.ipynb)，通过这份代码，你可以了解GPT模型的构建方法以及训练和推理的过程，我们以加法运算和文本生成为例给出了GPT-2的运行结果。
Q: 我需要配置很复杂的运行环境吗？
A: 完全不需要哦，只需要PyTorch版本号1.6.0就可以，CPU也可以运行哈。同时我们在代码中给出了Colab链接(https://colab.research.google.com/drive/12RHUqxUffGz7-qGIGrbLvLkPZmfcl9tQ?usp=sharing)，你可以借助Colab的GPU资源更快地训练模型。
Q: 我需要下载checkpoints吗？
A: 完全不需要，我们的模型是从头开始训练，这样可以帮助大家更好地了解GPT-2完整的运行方式。
```
```markdown
Q: what is this?
A: This is a GPT-2 code (GPT_2 Tutorials.ipynb). Through this code, you can understand the construction method of the GPT model and the process of training and inference. We take the addition operation and text generation as an example to give the running result of GPT-2.
Q: Do I need to configure a complicated operating environment?
A: No need at all, only PyTorch version 1.6.0 is required, and the CPU can also run. At the same time we give the Colab link in the code (https://colab.research.google.com/drive/12RHUqxUffGz7-qGIGrbLvLkPZmfcl9tQ?usp=sharing), you can use Colab's GPU resources to train models faster.
Q: Do I need to download checkpoints?
A: No need at all. Our model is trained from scratch, which can help everyone better understand the complete operation of GPT-2.
```
# Code
* [Jupyter](https://github.com/wzy6642/GPT-2-Tutorials/blob/main/GPT_2%20Tutorials.ipynb)
* [Colab](https://colab.research.google.com/drive/12RHUqxUffGz7-qGIGrbLvLkPZmfcl9tQ?usp=sharing)
# Package
PyTorch == 1.6.0
# Reference
* [minGPT](https://github.com/karpathy/minGPT)
* [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
